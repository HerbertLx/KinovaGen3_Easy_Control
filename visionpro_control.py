import sys
import os
import time
import numpy as np
from scipy.spatial.transform import Rotation as R

try:
    from kinova_manage import KinovaManager
except ImportError:
    print("âš ï¸ è¯·ç¡®ä¿ kinova_manage.py åœ¨å½“å‰ç›®å½•ä¸‹")
    sys.exit(1)

from avp_stream import VisionProStreamer

# ================= é…ç½®åŒºåŸŸ =================
AVP_IP = "192.168.1.223"
ROBOT_IP = "192.168.8.10"

SCALE_FACTOR = 0.5       
MAX_LINEAR_VEL = 0.3     # m/s
MAX_ANGULAR_VEL = 40.0   # deg/s
PINCH_THRESHOLD = 0.02
NO_OBSERVATION_THRESHOLD = 0.0005

# å·¦æ‰‹æ§åˆ¶å‚æ•°
LEFT_ROLL_CENTER = 3.0    # è™å£å‘å³ä¸ºåŸºå‡† (rad)
LEFT_ROLL_DEADZONE = 0.4  # æ­»åŒºï¼Œé˜²æ­¢æ¼‚ç§»
LEFT_ROLL_SENSITIVITY = 30.0 # æ—‹è½¬çµæ•åº¦
# ===========================================

class VisionProTeleop:
    def __init__(self):
        print(f"Connecting to Vision Pro at {AVP_IP}...")
        self.avp = VisionProStreamer(ip=AVP_IP)
        self.avp.start_webrtc()
        
        print(f"Connecting to Kinova at {ROBOT_IP}...")
        self.arm = KinovaManager(ip_address=ROBOT_IP)
        self.arm.connect()
        
        self.clutch_engaged = False
        self.start_hand_pos = None
        self.start_robot_pos = None
        self.start_hand_rot = None  
        self.start_robot_rot = None 
        self.last_gripper_closed = None
        self.is_active = False

    def get_hand_data(self, data):
        matrix = data['right_wrist'][0] 
        pos = matrix[:3, 3]
        rot = R.from_matrix(matrix[:3, :3])
        return pos, rot

    def transform_pos_avp_to_robot(self, avp_delta):
        dx, dy, dz = avp_delta
        return np.array([dy, -dx, dz])

    def transform_rot_avp_to_robot(self, delta_rot_obj):
        # å¤„ç†å³æ‰‹å§¿æ€æ˜ å°„ (Pitch å’Œ Yaw)
        euler = delta_rot_obj.as_euler('xyz', degrees=True)
        # æ’é™¤åŸæœ¬çš„ Z è½´æ—‹è½¬(é¡ºé€†æ—¶é’ˆ)ï¼Œå› ä¸ºç°åœ¨ç”±å·¦æ‰‹æ§åˆ¶
        robot_euler = [euler[1], -euler[0], 0] 
        return R.from_euler('xyz', robot_euler, degrees=True)

    def run(self):
        print("\nğŸš€ æ··åˆæ§åˆ¶é¥æ“ä½œå·²å¯åŠ¨")
        print("æ“ä½œï¼šå·¦æ‰‹æåˆæ¿€æ´»ï¼Œå³æ‰‹æ§åˆ¶ä½ç½®+ä¿¯ä»°åèˆªï¼Œå·¦æ‰‹ Roll æ§åˆ¶é¡ºé€†æ—¶é’ˆ")
        
        try:
            while True:
                r = self.avp.get_latest()
                if not r: continue

                # 1. æ¿€æ´»åˆ¤æ–­
                left_pinch = r['left_pinch_distance']
                if left_pinch >= NO_OBSERVATION_THRESHOLD:
                    self.is_active = left_pinch < PINCH_THRESHOLD
                
                curr_hand_pos, curr_hand_rot = self.get_hand_data(r)

                if self.is_active:
                    status = self.arm.get_status()
                    if not status: continue
                    b = status.base
                    
                    if not self.clutch_engaged:
                        print("ğŸŸ¢ æ§åˆ¶æ¿€æ´»")
                        self.clutch_engaged = True
                        self.start_hand_pos = curr_hand_pos
                        self.start_hand_rot = curr_hand_rot
                        self.start_robot_pos = np.array([b.tool_pose_x, b.tool_pose_y, b.tool_pose_z])
                        self.start_robot_rot = R.from_euler('xyz', [b.tool_pose_theta_x, b.tool_pose_theta_y, b.tool_pose_theta_z], degrees=True)

                    # --- 2. ä½ç½®æ§åˆ¶ (å³æ‰‹) ---
                    delta_hand_pos = curr_hand_pos - self.start_hand_pos
                    target_robot_pos = self.start_robot_pos + self.transform_pos_avp_to_robot(delta_hand_pos) * SCALE_FACTOR
                    curr_robot_pos = np.array([b.tool_pose_x, b.tool_pose_y, b.tool_pose_z])
                    lin_vel = (target_robot_pos - curr_robot_pos) * 2.5 

                    # --- 3. å§¿æ€æ§åˆ¶ (å³æ‰‹ Pitch/Yaw) ---
                    delta_rot_hand = curr_hand_rot * self.start_hand_rot.inv()
                    delta_rot_robot = self.transform_rot_avp_to_robot(delta_rot_hand)
                    target_robot_rot = delta_rot_robot * self.start_robot_rot
                    curr_robot_rot = R.from_euler('xyz', [b.tool_pose_theta_x, b.tool_pose_theta_y, b.tool_pose_theta_z], degrees=True)
                    error_rot = target_robot_rot * curr_robot_rot.inv()
                    ang_vel_vec = error_rot.as_rotvec(degrees=True) * 2.0 

                    # --- 4. é¡ºé€†æ—¶é’ˆæ—‹è½¬ (å·¦æ‰‹ Roll) ---
                    left_roll = r['left_wrist_roll']
                    if left_roll < 0:
                        left_roll += 2 * np.pi
                    # è®¡ç®—ç›¸å¯¹äºâ€œè™å£å‘å³(3.0)â€çš„åç§»
                    # å‘ä¸Šé€šå¸¸ roll å‡å° (è¶‹å‘0æˆ–è´Ÿ)ï¼Œå‘ä¸‹è¶‹å‘ 1.5
                    roll_diff = left_roll - LEFT_ROLL_CENTER
                    
                    # é€»è¾‘æ˜ å°„ï¼š
                    # å‘ä¸Š (roll < 1.5) -> é¡ºæ—¶é’ˆ (+WZ)
                    # å‘å³ (roll ~ 3.0) -> åœæ­¢
                    # å‘ä¸‹ (roll ~ 1.5) -> é€†æ—¶é’ˆ (-WZ)
                    
                    w_z_override = 0.0
                    if abs(roll_diff) > LEFT_ROLL_DEADZONE:
                        # å¦‚æœ roll å€¼å˜å°ï¼ˆå‘ä¸Šï¼‰ï¼Œæˆ‘ä»¬å¸Œæœ›è¾“å‡ºæ­£çš„ w_z
                        # è¿™é‡Œç”¨ 3.0 å‡å»å½“å‰å€¼ï¼Œè¿™æ ·å‘ä¸Š(æ¯”å¦‚1.0)å°±ä¼šå¾—åˆ°æ­£æ•°
                        w_z_override = (LEFT_ROLL_CENTER - left_roll) * LEFT_ROLL_SENSITIVITY


                    # --- 5. å¤¹çˆªæ§åˆ¶ ---
                    right_pinch = r['right_pinch_distance']
                    if self.last_gripper_closed:
                        current_gripper_closed = right_pinch <= PINCH_THRESHOLD + 0.01
                    else:
                        current_gripper_closed = right_pinch <= PINCH_THRESHOLD - 0.01

                    if (current_gripper_closed != self.last_gripper_closed) and (right_pinch >= NO_OBSERVATION_THRESHOLD):
                        print(f"cur = {current_gripper_closed}, last = {self.last_gripper_closed}, right_pinch = {right_pinch}")
                        target_val = 100.0 if current_gripper_closed else 60
                        self.arm.control_gripper(target_val, dual_grip=False)
                        self.last_gripper_closed = current_gripper_closed

                    # --- 6. é€Ÿåº¦åˆæˆä¸å‘é€ ---
                    # é™é€Ÿ
                    lin_speed = np.linalg.norm(lin_vel)
                    if lin_speed > MAX_LINEAR_VEL: lin_vel = (lin_vel / lin_speed) * MAX_LINEAR_VEL
                    
                    # æœ€ç»ˆé€Ÿåº¦å‘é‡ [Vx, Vy, Vz, Wx, Wy, Wz]
                    # æˆ‘ä»¬ç”¨ ang_vel_vec çš„ X å’Œ Y å¤„ç†ä¿¯ä»°åèˆªï¼Œç”¨ w_z_override å¤„ç†å·¦æ‰‹æ§åˆ¶çš„æ—‹è½¬
                    velocities = [
                        lin_vel[0], lin_vel[1], lin_vel[2], 
                        ang_vel_vec[0], ang_vel_vec[1], w_z_override
                    ]
                    
                    # å…¨å±€è§’é€Ÿåº¦é™é€Ÿ
                    ang_speed = np.linalg.norm(velocities[3:])
                    if ang_speed > MAX_ANGULAR_VEL:
                        scale = MAX_ANGULAR_VEL / ang_speed
                        velocities[3:] = [v * scale for v in velocities[3:]]

                    self.arm.move_velocity(velocities, duration_ms=100)

                else:
                    if self.clutch_engaged:
                        print("ğŸ”´ æ§åˆ¶æ–­å¼€")
                        self.clutch_engaged = False
                        self.arm.move_velocity([0]*6, duration_ms=0)

                time.sleep(0.02)

        except KeyboardInterrupt:
            pass
        finally:
            self.arm.disconnect()

if __name__ == "__main__":
    VisionProTeleop().run()